# Published Benchmark

Many Deephaven benchmarks are published to the [deephaven-benchmark](https://storage.googleapis.com/deephaven-benchmark) GCloud bucket, 
accessible only through Google's storage API. Benchmarks are organized in the bucket in much the same ways as the 
[results generated from the command line](CollectedResults.md).

The easiest way to access the published benchmark results is by running the following Deephaven query code snippet
in an instance of the Deephaven Engine.

````
from urllib.request import urlopen

script_uri = 'https://storage.googleapis.com/deephaven-benchmark/benchmark_tables.dh.py'
with urlopen(script_uri) as r:
    benchmark_category_arg = 'release'  # release | nightly    
    benchmark_max_runs_arg = 10  # Latest X runs to include   
    exec(r.read().decode(), globals(), locals())
````

This will download the available benchmarks for the given benchmark category (release or nightly), merge test runs together, and generate some 
useful Deephaven tables that can be used to explore the benchmarks.

Requirements:
- [Deephaven 0.23.0 or higher](https://deephaven.io/core/docs/tutorials/quickstart/)
- 4G RAM allocated to Deephaven Server VM (The Default)

## Tables Generated By The Script

- bench_results: A merge of all available benchmark runs for a category
- bench_platforms: A merge the JVM configuration and hardware for the benchmark runs
- bench_metrics: A merge of the JVM metrics taken before and after each running
- bench_metrics_diff: The difference of the before and after metrics for each benchmark
- bench_results_diff: Bench results with some metrics diffs added as columns
- bench_results_change: Bench results with analysis of variability and rate change compared to past runs

